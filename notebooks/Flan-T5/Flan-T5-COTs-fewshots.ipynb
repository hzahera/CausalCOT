{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba48adbe-d86f-4387-ab40-71c2884e5ace",
   "metadata": {},
   "source": [
    "### Specify the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ff1d73b-ef29-41a2-9b6d-7811efc64e43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specify the name of dataset: \"hotpotqa_valid_original_split.csv\", \"gooaq_valid_original_split.csv\", or \"msmarco_valid_original_split.csv\"\n",
    "dataset_name= \"msmarco_valid_original_split.csv\"\n",
    "\n",
    "path= \"../../dataset/test/\"+dataset_name\n",
    "\n",
    "out_dir='../../output/Flan-T5-results/COTs+fewshot/'\n",
    "\n",
    "# name of the fine-tuned model, the pre-trained model is named: \"msmarco-original-split/\", \"hotpotqa-original-split/\" or \"gooaq-original-split/\"\n",
    "model_name= \"google/flan-t5-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ddadf62-f345-4322-8129-1ac91ed12eb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "few_shot= \"\"\"\n",
    "### example questions ### \\n\n",
    "[question_1]: How does smoking cause cancer?\\n\n",
    "[answer_1]: \n",
    "Smoking damages the DNA in our cells, which controls how they grow and behave. Smoking has many harmful chemicals, such as BP, that can attach to DNA and bend it out of shape . \n",
    "This can stop DNA from working properly and cause mutations that lead to cancer. Smoking can cause many types of cancer, such as lung, mouth, and bladder cancer . \n",
    "The more and longer a person smokes, the higher their cancer risk. Quitting smoking can lower the risk, but it may take years to undo the damage.The best way to avoid smoking-related cancer is to never smoke or quit as soon as possible.\n",
    "\n",
    "\\n\\n\n",
    "[question_2]: How does an earthquake cause a tsunami?\\n\n",
    "[answer_2]: \n",
    "An earthquake causes a tsunami by displacing a large amount of water in the ocean. When two tectonic plates collide or slide past each other, they can create a sudden movement of the sea floor, which lifts or drops the water above it. \n",
    "This creates a series of waves that travel across the ocean at high speeds. The waves can grow larger and more destructive as they approach shallow coastal areas, where the water depth decreases and the wave height increases. \n",
    "Earthquakes are the most common cause of tsunamis, but they can also be triggered by volcanic eruptions or landslides\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fca377-22c1-4a62-9989-df026de45fd3",
   "metadata": {},
   "source": [
    "### Configuration of Flan-T5 model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c87429fb-a1c3-48b0-80e7-cc0d3c96e32f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, set_seed\n",
    "set_seed(42)\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name, device_map=\"auto\", load_in_8bit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "047d217c-4904-4c92-be92-3510a3b8fed0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_model(input_string, **generator_args):\n",
    "    \n",
    "    input_ids = tokenizer(input_string, max_length=1000,truncation=True, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    \n",
    "    res = model.generate(input_ids, max_new_tokens=200, **generator_args)\n",
    "    \n",
    "    return tokenizer.batch_decode(res, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18159c9-876c-4dc0-9132-26e4c778a1a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2a51d7c-4acd-47ce-8840-cb85473cf21d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42560610-634d-4b9c-a478-bf9f16f8cb83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_df= pd.read_csv(path)\n",
    "\n",
    "dataset_df['generated_answer']=\"\"\n",
    "\n",
    "#iterate over the questions and answers: \n",
    "for row in dataset_df.itertuples():\n",
    "    \n",
    "    if row.context_processed !='':\n",
    "        input_query= row.question_processed+ \"\\n Find the answer of the question from the context:\\n \"+row.context_processed+'\\n Think step by step to answer like these examples: \\n'+few_shot\n",
    "    else:\n",
    "        input_query= \"Let's think step by step to answer the question: \"+row.question_processed+few_shot\n",
    "    \n",
    "    generated_answer=run_model(input_query)\n",
    "        \n",
    "    dataset_df.loc[row.Index,'generated_answer']= generated_answer[0]\n",
    "\n",
    "dataset_df.to_csv(out_dir+'/'+dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70360c3d-331e-43c2-b0d6-1b50ac97a2f7",
   "metadata": {},
   "source": [
    "### Evaluation using EM and F1 metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45647d1a-c0fd-48e6-be76-ca4a2ceada31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../src')\n",
    "\n",
    "import measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fec995-dc8b-481e-a4ff-ade75f2048c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " os.chdir(out_dir)\n",
    "\n",
    "def evaluate_unifiedqa(predictions, answers):\n",
    "    \n",
    "    result = {}\n",
    "    result['checkpoint'] = model_name\n",
    "    result['metrics'] = measures.all_metrics(predictions, answers)\n",
    "    result['predictions'] = predictions\n",
    "\n",
    "   \n",
    "    filename=dataset_name.split('.')[0]\n",
    "    filename=filename+\".json\"\n",
    "    \n",
    "    with open(filename, 'w+') as file:\n",
    "        json.dump(result, file, indent=4)\n",
    "        \n",
    "    print ('results saved at ', out_dir+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41618dd0-8f65-4b5b-9a25-eafe20ad3cb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions= dataset_df['generated_answer'].tolist()\n",
    "answers= dataset_df['answer_processed'].tolist()\n",
    "\n",
    "answers= [[answer] for answer in answers]\n",
    "\n",
    "evaluate_unifiedqa(predictions, answers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "119b80cd-3759-4b86-acaa-6b83eaa8f986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print ('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c362c36d-633c-4b76-aa0f-4017cc6e7895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causalQA",
   "language": "python",
   "name": "causalqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
